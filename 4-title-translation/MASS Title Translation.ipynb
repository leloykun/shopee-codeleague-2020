{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Install fairseq"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip3 install -q fairseq==0.7.1","execution_count":1,"outputs":[{"output_type":"stream","text":"\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\r\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Download codes, data, and models"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!git clone https://leloykun:%40Leloy123@github.com/leloykun/mass-title-translation.git","execution_count":2,"outputs":[{"output_type":"stream","text":"Cloning into 'mass-title-translation'...\nremote: Enumerating objects: 36, done.\u001b[K\nremote: Counting objects: 100% (36/36), done.\u001b[K\nremote: Compressing objects: 100% (32/32), done.\u001b[K\nremote: Total 36 (delta 3), reused 36 (delta 3), pack-reused 0\u001b[K\nUnpacking objects: 100% (36/36), done.\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"cd mass-title-translation","execution_count":3,"outputs":[{"output_type":"stream","text":"/kaggle/working/mass-title-translation\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!gsutil cp gs://shopee-title-translation/mass/models/checkpoint_kaggle_sup_ft3.pt models/checkpoint_best.pt","execution_count":4,"outputs":[{"output_type":"stream","text":"CommandException: Incorrect option(s) specified. Usage:\r\n\r\n  gsutil cp [OPTION]... src_url dst_url\r\n  gsutil cp [OPTION]... src_url... dst_url\r\n  gsutil cp [OPTION]... -I dst_url\r\n\r\nFor additional help run:\r\n  gsutil help cp\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir data","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir data/processed","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!gsutil -m cp -r gs://shopee-title-translation/data/processed data","execution_count":11,"outputs":[{"output_type":"stream","text":"Copying gs://shopee-title-translation/data/processed/dict.en.txt...\nCopying gs://shopee-title-translation/data/processed/dict.zh.txt...\nCopying gs://shopee-title-translation/data/processed/test.en-zh.en...           \nCopying gs://shopee-title-translation/data/processed/precalc_vocabs/vocab.zh... \nCopying gs://shopee-title-translation/data/processed/test.en...                 \nCopying gs://shopee-title-translation/data/processed/precalc_vocabs/codes...    \nCopying gs://shopee-title-translation/data/processed/precalc_vocabs/vocab.en... \nCopying gs://shopee-title-translation/data/processed/test.en-zh.en.bin...\nCopying gs://shopee-title-translation/data/processed/precalc_vocabs/vocab.en-zh...\nCopying gs://shopee-title-translation/data/processed/test.en-zh.en.idx...       \nCopying gs://shopee-title-translation/data/processed/test.en-zh.en.pth...       \nCopying gs://shopee-title-translation/data/processed/test.en-zh.en.tok...       \nCopying gs://shopee-title-translation/data/processed/test.en-zh.zh...           \nCopying gs://shopee-title-translation/data/processed/test.en-zh.zh.bin...\nCopying gs://shopee-title-translation/data/processed/test.en-zh.zh.idx...       \nCopying gs://shopee-title-translation/data/processed/test.en-zh.zh.pth...       \nCopying gs://shopee-title-translation/data/processed/test.en-zh.zh.tok...       \nCopying gs://shopee-title-translation/data/processed/test.en.bin...             \nCopying gs://shopee-title-translation/data/processed/test.en.idx...\nCopying gs://shopee-title-translation/data/processed/test.en.pth...             \nCopying gs://shopee-title-translation/data/processed/test.en.tok...             \nCopying gs://shopee-title-translation/data/processed/test.raw.en...             \nCopying gs://shopee-title-translation/data/processed/test.raw.en.pth...         \nCopying gs://shopee-title-translation/data/processed/test.raw.en.tok...         \nCopying gs://shopee-title-translation/data/processed/test.raw.zh...             \nCopying gs://shopee-title-translation/data/processed/test.raw.zh.pth...         \nCopying gs://shopee-title-translation/data/processed/test.raw.zh.tok...         \nCopying gs://shopee-title-translation/data/processed/test.zh...                 \nCopying gs://shopee-title-translation/data/processed/test.zh.bin...             \nCopying gs://shopee-title-translation/data/processed/test.zh.idx...             \nCopying gs://shopee-title-translation/data/processed/test.zh.pth...             \nCopying gs://shopee-title-translation/data/processed/test.zh.tok...             \nCopying gs://shopee-title-translation/data/processed/train.en...                \nCopying gs://shopee-title-translation/data/processed/train.en-zh.en...          \nCopying gs://shopee-title-translation/data/processed/train.en-zh.en.bin...      \nCopying gs://shopee-title-translation/data/processed/train.en-zh.en.idx...      \nCopying gs://shopee-title-translation/data/processed/train.en-zh.en.pth...      \nCopying gs://shopee-title-translation/data/processed/train.en-zh.en.tok...\nCopying gs://shopee-title-translation/data/processed/train.en-zh.zh...          \nCopying gs://shopee-title-translation/data/processed/train.en-zh.zh.bin...      \nCopying gs://shopee-title-translation/data/processed/train.en-zh.zh.idx...      \nCopying gs://shopee-title-translation/data/processed/train.en-zh.zh.tok...      \nCopying gs://shopee-title-translation/data/processed/train.en-zh.zh.pth...      \nCopying gs://shopee-title-translation/data/processed/train.en.bin...            \nCopying gs://shopee-title-translation/data/processed/train.en.idx...            \nCopying gs://shopee-title-translation/data/processed/train.en.pth...            \nCopying gs://shopee-title-translation/data/processed/train.en.tok...\nCopying gs://shopee-title-translation/data/processed/train.raw.en...            \nCopying gs://shopee-title-translation/data/processed/train.raw.en.pth...        \nCopying gs://shopee-title-translation/data/processed/train.raw.en.tok...        \nCopying gs://shopee-title-translation/data/processed/train.raw.zh...            \nCopying gs://shopee-title-translation/data/processed/train.raw.zh.pth...        \nCopying gs://shopee-title-translation/data/processed/train.raw.zh.tok...        \nCopying gs://shopee-title-translation/data/processed/train.zh...                \nCopying gs://shopee-title-translation/data/processed/train.zh.bin...            \nCopying gs://shopee-title-translation/data/processed/train.zh.idx...            \nCopying gs://shopee-title-translation/data/processed/train.zh.pth...            \nCopying gs://shopee-title-translation/data/processed/train.zh.tok...            \nCopying gs://shopee-title-translation/data/processed/valid.en...                \nCopying gs://shopee-title-translation/data/processed/valid.en-zh.en...          \nCopying gs://shopee-title-translation/data/processed/valid.en-zh.en.bin...      \nCopying gs://shopee-title-translation/data/processed/valid.en-zh.en.idx...      \nCopying gs://shopee-title-translation/data/processed/valid.en-zh.en.pth...      \nCopying gs://shopee-title-translation/data/processed/valid.en-zh.en.tok...      \nCopying gs://shopee-title-translation/data/processed/valid.en-zh.zh...          \nCopying gs://shopee-title-translation/data/processed/valid.en-zh.zh.bin...      \nCopying gs://shopee-title-translation/data/processed/valid.en-zh.zh.idx...      \nCopying gs://shopee-title-translation/data/processed/valid.en-zh.zh.pth...      \nCopying gs://shopee-title-translation/data/processed/valid.en-zh.zh.tok...      \nCopying gs://shopee-title-translation/data/processed/valid.en.bin...            \nCopying gs://shopee-title-translation/data/processed/valid.en.idx...            \nCopying gs://shopee-title-translation/data/processed/valid.en.pth...            \nCopying gs://shopee-title-translation/data/processed/valid.en.tok...            \nCopying gs://shopee-title-translation/data/processed/valid.raw.en...\nCopying gs://shopee-title-translation/data/processed/valid.raw.en.pth...        \nCopying gs://shopee-title-translation/data/processed/valid.raw.en.tok...        \nCopying gs://shopee-title-translation/data/processed/valid.raw.zh...            \nCopying gs://shopee-title-translation/data/processed/valid.raw.zh.pth...        \nCopying gs://shopee-title-translation/data/processed/valid.raw.zh.tok...        \nCopying gs://shopee-title-translation/data/processed/valid.zh...                \nCopying gs://shopee-title-translation/data/processed/valid.zh.bin...            \nCopying gs://shopee-title-translation/data/processed/valid.zh.idx...            \nCopying gs://shopee-title-translation/data/processed/valid.zh.pth...            \nCopying gs://shopee-title-translation/data/processed/valid.zh.tok...            \n\\ [84/84 files][609.6 MiB/609.6 MiB] 100% Done                                  \nOperation completed over 84 objects/609.6 MiB.                                   \n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls data/processed","execution_count":12,"outputs":[{"output_type":"stream","text":"dict.en.txt        test.raw.zh         train.en.pth        valid.en-zh.zh.idx\r\ndict.zh.txt        test.raw.zh.pth     train.en.tok        valid.en-zh.zh.pth\r\n\u001b[0m\u001b[01;34mprecalc_vocabs\u001b[0m/    test.raw.zh.tok     train.raw.en        valid.en-zh.zh.tok\r\ntest.en            test.zh             train.raw.en.pth    valid.en.bin\r\ntest.en-zh.en      test.zh.bin         train.raw.en.tok    valid.en.idx\r\ntest.en-zh.en.bin  test.zh.idx         train.raw.zh        valid.en.pth\r\ntest.en-zh.en.idx  test.zh.pth         train.raw.zh.pth    valid.en.tok\r\ntest.en-zh.en.pth  test.zh.tok         train.raw.zh.tok    valid.raw.en\r\ntest.en-zh.en.tok  train.en            train.zh            valid.raw.en.pth\r\ntest.en-zh.zh      train.en-zh.en      train.zh.bin        valid.raw.en.tok\r\ntest.en-zh.zh.bin  train.en-zh.en.bin  train.zh.idx        valid.raw.zh\r\ntest.en-zh.zh.idx  train.en-zh.en.idx  train.zh.pth        valid.raw.zh.pth\r\ntest.en-zh.zh.pth  train.en-zh.en.pth  train.zh.tok        valid.raw.zh.tok\r\ntest.en-zh.zh.tok  train.en-zh.en.tok  valid.en            valid.zh\r\ntest.en.bin        train.en-zh.zh      valid.en-zh.en      valid.zh.bin\r\ntest.en.idx        train.en-zh.zh.bin  valid.en-zh.en.bin  valid.zh.idx\r\ntest.en.pth        train.en-zh.zh.idx  valid.en-zh.en.idx  valid.zh.pth\r\ntest.en.tok        train.en-zh.zh.pth  valid.en-zh.en.pth  valid.zh.tok\r\ntest.raw.en        train.en-zh.zh.tok  valid.en-zh.en.tok\r\ntest.raw.en.pth    train.en.bin        valid.en-zh.zh\r\ntest.raw.en.tok    train.en.idx        valid.en-zh.zh.bin\r\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Pretraining"},{"metadata":{},"cell_type":"markdown","source":"### Fine-tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dir = \"data/processed\"\nuser_dir = \"mass\"\nsave_dir = \"models\"\nmodel = \"checkpoint_best.pt\"\n\nseed=0\nmax_tokens=2048 # for 16GB GPUs\nupdate_freq=1\ndropout=0.1\nattention_heads=4\nembed_dim=512\nffn_embed_dim=1024\nencoder_layers=6\ndecoder_layers=4\nword_mask=0.3\n\nend_epoch = 30\n!echo \"start epoch $end_epoch\" && \\\nfairseq-train $data_dir \\\n    --user-dir $user_dir \\\n    --task xmasked_seq2seq \\\n    --source-langs en,zh \\\n    --target-langs en,zh \\\n    --langs en,zh \\\n    --arch xtransformer \\\n    --mt_steps zh-en,en-zh \\\n    --save-dir $save_dir \\\n    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n    --lr-scheduler inverse_sqrt --lr 0.00005 --min-lr 1e-09 \\\n    --criterion label_smoothed_cross_entropy \\\n    --lm-bias --lazy-load --seed $seed \\\n    --log-format json \\\n    --max-tokens $max_tokens --update-freq $update_freq \\\n    --encoder-normalize-before  --decoder-normalize-before \\\n    --dropout $dropout --relu-dropout $dropout --attention-dropout $dropout \\\n    --decoder-attention-heads $attention_heads --encoder-attention-heads $attention_heads \\\n    --decoder-embed-dim $embed_dim --encoder-embed-dim $embed_dim \\\n    --decoder-ffn-embed-dim $ffn_embed_dim --encoder-ffn-embed-dim $ffn_embed_dim \\\n    --encoder-layers $encoder_layers --decoder-layers $decoder_layers \\\n    --max-update 100000000 --max-epoch $end_epoch \\\n    --keep-last-epochs 1 --log-interval 100 \\\n    --share-decoder-input-output-embed \\\n    --valid-lang-pairs en-zh \\\n    --word_mask $word_mask \\\n    --ddp-backend=no_c10d \\\n    --restore-file $model \\\n    --no-epoch-checkpoints \\\n    --skip-invalid-size-inputs-valid-test","execution_count":13,"outputs":[{"output_type":"stream","text":"start epoch 30\nNamespace(activation_dropout=0.1, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, arch='xtransformer', attention_dropout=0.1, bucket_cap_mb=25, clip_norm=0.0, cpu=False, criterion='label_smoothed_cross_entropy', curriculum=0, data='data/processed', dataset_impl='cached', ddp_backend='no_c10d', decoder_attention_heads=4, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=1024, decoder_input_dim=512, decoder_layers=4, decoder_learned_pos=False, decoder_normalize_before=True, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, encoder_attention_heads=4, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=1024, encoder_layers=6, encoder_learned_pos=False, encoder_normalize_before=True, find_unused_parameters=False, fix_batches_to_gpus=False, fp16=False, fp16_init_scale=128, fp16_scale_tolerance=0.0, fp16_scale_window=None, global_sync_iter=10, keep_interval_updates=-1, keep_last_epochs=1, label_smoothing=0.0, langs='en,zh', lazy_load=True, left_pad_source='True', left_pad_target='False', lm_bias=True, log_format='json', log_interval=100, lr=[5e-05], lr_scheduler='inverse_sqrt', mass_steps='', max_epoch=30, max_sentences=None, max_sentences_valid=None, max_source_positions=1024, max_target_positions=1024, max_tokens=2048, max_update=100000000, memory_efficient_fp16=False, memt_steps='', min_loss_scale=0.0001, min_lr=1e-09, mt_steps='zh-en,en-zh', no_epoch_checkpoints=True, no_progress_bar=False, no_save=False, no_token_positional_embeddings=False, num_workers=0, optimizer='adam', optimizer_overrides='{}', raw_text=False, reload_checkpoint=None, required_batch_size_multiple=8, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_best.pt', save_dir='models', save_interval=1, save_interval_updates=0, seed=0, sentence_avg=False, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=True, source_lang=None, source_langs='en,zh', target_lang=None, target_langs='en,zh', task='xmasked_seq2seq', tbmf_wrapper=False, tensorboard_logdir='', threshold_loss_scale=None, train_subset='train', update_freq=[1], use_bmuf=False, user_dir='mass', valid_lang_pairs='en-zh', valid_subset='valid', validate_interval=1, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0, word_mask=0.3, word_mask_keep_rand='0.1,0.1,0.8')\n| [en] dictionary: 28778 types\n| [zh] dictionary: 56317 types\n| bilingual valid en-zh.en: 4999 examples\n| bilingual valid en-zh.zh: 4999 examples\nXTransformerModel(\n  (encoders): ModuleDict(\n    (en): XTransformerEncoder(\n      (embed_tokens): Embedding(28778, 512, padding_idx=1)\n      (embed_positions): SinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (1): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (2): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (3): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (4): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (5): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n    (zh): XTransformerEncoder(\n      (embed_tokens): Embedding(56317, 512, padding_idx=1)\n      (embed_positions): SinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (1): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (2): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (3): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (4): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (5): TransformerEncoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (decoders): ModuleDict(\n    (en): XTransformerDecoder(\n      (embed_tokens): Embedding(28778, 512, padding_idx=1)\n      (embed_positions): SinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0): TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (1): TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (2): TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (3): TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n    (zh): XTransformerDecoder(\n      (embed_tokens): Embedding(56317, 512, padding_idx=1)\n      (embed_positions): SinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0): TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (1): TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (2): TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n        (3): TransformerDecoderLayer(\n          (self_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): MultiheadAttention(\n            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=512, out_features=1024, bias=True)\n          (fc2): Linear(in_features=1024, out_features=512, bias=True)\n          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n)\n| model xtransformer, criterion LabelSmoothedCrossEntropyCriterion\n| num. model params: 94041600 (num. trained: 94041600)\n","name":"stdout"},{"output_type":"stream","text":"| training on 1 GPUs\n| max tokens per GPU = 2048 and max sentences per GPU = None\n| no existing checkpoint found models/checkpoint_best.pt\n| loading train data for epoch 0\n| bilingual train en-zh.en: 12000 examples\n| bilingual train en-zh.zh: 12000 examples\n/opt/conda/conda-bld/pytorch_1591914880026/work/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n\tadd_(Number alpha, Tensor other)\nConsider using one of the following signatures instead:\n\tadd_(Tensor other, *, Number alpha)\n{\"epoch\": 1, \"update\": 0.935, \"loss\": \"26.899\", \"nll_loss\": \"26.899\", \"ppl\": \"125112004.08\", \"wps\": \"10951\", \"ups\": \"3\", \"wpb\": \"3088.574\", \"bsz\": \"221.149\", \"num_updates\": \"101\", \"lr\": \"5e-05\", \"gnorm\": \"1.236\", \"clip\": \"0.000\", \"oom\": \"0.000\", \"wall\": \"30\", \"train_wall\": \"27\", \"zh-en:loss\": \"12.9049\", \"zh-en:nll_loss\": \"12.9049\", \"zh-en:ntokens\": \"1534.35\", \"zh-en:nsentences\": \"110.574\", \"zh-en:sample_size\": \"1534.35\", \"en-zh:loss\": \"13.9938\", \"en-zh:nll_loss\": \"13.9938\", \"en-zh:ntokens\": \"1554.23\", \"en-zh:nsentences\": \"110.574\", \"en-zh:sample_size\": \"1554.23\"}\n{\"epoch\": 1, \"train_loss\": \"26.737\", \"train_nll_loss\": \"26.737\", \"train_ppl\": \"111842360.87\", \"train_wps\": \"10976\", \"train_ups\": \"3\", \"train_wpb\": \"3099.402\", \"train_bsz\": \"224.299\", \"train_num_updates\": \"107\", \"train_lr\": \"5e-05\", \"train_gnorm\": \"1.235\", \"train_clip\": \"0.000\", \"train_oom\": \"0.000\", \"train_wall\": \"31\", \"train_train_wall\": \"28\", \"train_zh-en:loss\": \"12.8243\", \"train_zh-en:nll_loss\": \"12.8243\", \"train_zh-en:ntokens\": \"1539.33\", \"train_zh-en:nsentences\": \"112.15\", \"train_zh-en:sample_size\": \"1539.33\", \"train_en-zh:loss\": \"13.9125\", \"train_en-zh:nll_loss\": \"13.9125\", \"train_en-zh:ntokens\": \"1560.07\", \"train_en-zh:nsentences\": \"112.15\", \"train_en-zh:sample_size\": \"1560.07\"}\n{\"epoch\": 1, \"valid_loss\": \"13.265\", \"valid_nll_loss\": \"13.265\", \"valid_ppl\": \"9843.99\", \"valid_num_updates\": \"107\", \"valid_en-zh:loss\": \"13.261\", \"valid_en-zh:nll_loss\": \"13.261\", \"valid_en-zh:ntokens\": \"1257.15\", \"valid_en-zh:nsentences\": \"96.1346\", \"valid_en-zh:sample_size\": \"1257.15\"}\n| saved checkpoint models/checkpoint_best.pt (epoch 1 @ 107 updates) (writing took 3.9384727478027344 seconds)\n^C\nTraceback (most recent call last):\n  File \"/opt/conda/bin/fairseq-train\", line 8, in <module>\n    sys.exit(cli_main())\n  File \"/opt/conda/lib/python3.7/site-packages/fairseq_cli/train.py\", line 302, in cli_main\n    main(args)\n  File \"/opt/conda/lib/python3.7/site-packages/fairseq_cli/train.py\", line 80, in main\n    train(args, trainer, task, epoch_itr)\n  File \"/opt/conda/lib/python3.7/site-packages/fairseq_cli/train.py\", line 121, in train\n    log_output = trainer.train_step(samples)\n  File \"/opt/conda/lib/python3.7/site-packages/fairseq/trainer.py\", line 341, in train_step\n    self.optimizer.step()\n  File \"/opt/conda/lib/python3.7/site-packages/fairseq/optim/fairseq_optimizer.py\", line 91, in step\n    self.optimizer.step(closure)\n  File \"/opt/conda/lib/python3.7/site-packages/fairseq/optim/adam.py\", line 144, in step\n    exp_avg.mul_(beta1).add_(1 - beta1, grad)\nKeyboardInterrupt\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"gsutil cp models/checkpoint_best.pt gs://shopee-title-translation/mass/models/checkpoint_kaggle_sup_ft4.pt && \\\nrm models/*.pt && \\\ngsutil cp gs://shopee-title-translation/mass/models/checkpoint_kaggle_sup_ft4.pt models/checkpoint_best.pt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"MODEL=\"models/checkpoint_best.pt\"\nDATA_DIR=\"data/processed\"\nDEST_DIR=\"data/bt/model\"\nUSER_DIR=\"mass\"\nTEMP_DIR=\"data/tmp\"\n\nSTAGE=\"train\"\nSRC=\"en\"\nTGT=\"zh\"\n\nSRC_PREFIX=DATA_DIR+\"/\"+STAGE+\".raw\"\nDEST_PREFIX=DEST_DIR+\"/\"+STAGE+\".\"+SRC+\"-\"+TGT\n\nprint(SRC_PREFIX, DEST_PREFIX)\n\n!fairseq-interactive data/processed \\\n        --user-dir mass \\\n        -s zh -t en \\\n        --langs zh,en \\\n        --source-langs zh --target-langs en \\\n        --mt_steps zh-en \\\n        --task xmasked_seq2seq \\\n        --path models/checkpoint_best.pt \\\n        --beam 8 --remove-bpe  \\\n        --max-tokens 20000 --buffer-size 1500 \\\n        --input data/processed/train.raw.zh > data/tmp/train.zh-en.preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mkdir data/tmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ls data/processed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!gsutil cp data/tmp/train.en-zh.preds gs://shopee-title-translation/mass/train.en-zh.preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!gsutil cp data/tmp/train.zh-en.preds gs://shopee-title-translation/mass/train.zh-en.preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}