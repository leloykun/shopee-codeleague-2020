{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencc\n",
      "  Downloading OpenCC-1.1.1-py2.py3-none-win_amd64.whl (726 kB)\n",
      "Installing collected packages: opencc\n",
      "Successfully installed opencc-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install opencc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, gc, emoji, re\n",
    "\n",
    "import opencc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s2t.json Simplified Chinese to Traditional Chinese 簡體到繁體\n",
    "#t2s.json Traditional Chinese to Simplified Chinese 繁體到簡體\n",
    "#s2tw.json Simplified Chinese to Traditional Chinese (Taiwan Standard) 簡體到臺灣正體\n",
    "#tw2s.json Traditional Chinese (Taiwan Standard) to Simplified Chinese 臺灣正體到簡體\n",
    "#s2hk.json Simplified Chinese to Traditional Chinese (Hong Kong variant) 簡體到香港繁體\n",
    "#hk2s.json Traditional Chinese (Hong Kong variant) to Simplified Chinese 香港繁體到簡體\n",
    "#s2twp.json Simplified Chinese to Traditional Chinese (Taiwan Standard) with Taiwanese idiom 簡體到繁體（臺灣正體標準）並轉換爲臺灣常用詞彙\n",
    "#tw2sp.json Traditional Chinese (Taiwan Standard) to Simplified Chinese with Mainland Chinese idiom 繁體（臺灣正體標準）到簡體並轉換爲中國大陸常用詞彙\n",
    "#t2tw.json Traditional Chinese (OpenCC Standard) to Taiwan Standard 繁體（OpenCC 標準）到臺灣正體\n",
    "#hk2t.json Traditional Chinese (Hong Kong variant) to Traditional Chinese 香港繁體到繁體（OpenCC 標準）\n",
    "#t2hk.json Traditional Chinese (OpenCC Standard) to Hong Kong variant 繁體（OpenCC 標準）到香港繁體\n",
    "#t2jp.json Traditional Chinese Characters (Kyūjitai) to New Japanese Kanji (Shinjitai) 繁體（OpenCC 標準，舊字體）到日文新字體\n",
    "#jp2t.json New Japanese Kanji (Shinjitai) to Traditional Chinese Characters (Kyūjitai) 日文新字體到繁體（OpenCC 標準，舊字體）\n",
    "#tw2t.json Traditional Chinese (Taiwan standard) to Traditional Chinese 臺灣正體到繁體（OpenCC 標準）\n",
    "converter = opencc.OpenCC('tw2s.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tcn = pd.read_csv('product-translation-dataset/train_tcn.csv')\n",
    "df_train_en  = pd.read_csv('product-translation-dataset/train_en.csv')\n",
    "df_test_tcn  = pd.read_csv('product-translation-dataset/test_tcn.csv')\n",
    "df_dev_tcn = pd.read_csv('product-translation-dataset/dev_tcn.csv')\n",
    "df_dev_en  = pd.read_csv('product-translation-dataset/dev_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_tcn.columns = ['product_title', 'split']\n",
    "df_dev_tcn.columns = ['product_title', 'split']\n",
    "df_dev_en.columns = ['product_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tcn = df_train_tcn.dropna()\n",
    "df_train_en  = df_train_en.dropna()\n",
    "df_test_tcn  = df_test_tcn.dropna()\n",
    "df_dev_tcn   = df_dev_tcn.dropna()\n",
    "df_dev_en    = df_dev_en.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tcn = df_train_tcn[~((df_train_tcn[\"product_title\"].str.contains('\\n')) & \n",
    "                              (df_train_tcn[\"product_title\"].str.contains('\\\"')) & \n",
    "                              (df_train_tcn[\"product_title\"].str.contains(',')))]\n",
    "df_train_en  = df_train_en[~((df_train_en[\"product_title\"].str.contains('\\n')) & \n",
    "                             (df_train_en[\"product_title\"].str.contains('\\\"')) & \n",
    "                             (df_train_en[\"product_title\"].str.contains(',')))]\n",
    "df_test_tcn  = df_test_tcn[~((df_test_tcn[\"product_title\"].str.contains('\\n')) & \n",
    "                             (df_test_tcn[\"product_title\"].str.contains('\\\"')) & \n",
    "                             (df_test_tcn[\"product_title\"].str.contains(',')))]\n",
    "df_dev_tcn   = df_dev_tcn[~((df_dev_tcn[\"product_title\"].str.contains('\\n')) & \n",
    "                            (df_dev_tcn[\"product_title\"].str.contains('\\\"')) & \n",
    "                            (df_dev_tcn[\"product_title\"].str.contains(',')))]\n",
    "df_dev_en    = df_dev_en[~((df_dev_en[\"product_title\"].str.contains('\\n')) & \n",
    "                           (df_dev_en[\"product_title\"].str.contains('\\\"')) & \n",
    "                           (df_dev_en[\"product_title\"].str.contains(',')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tcn['product_title'] = df_train_tcn['product_title'].apply(converter.convert)\n",
    "df_train_en['product_title']  = df_train_en['product_title'].apply(converter.convert)\n",
    "df_test_tcn['product_title']  = df_test_tcn['product_title'].apply(converter.convert)\n",
    "df_dev_tcn['product_title']   = df_dev_tcn['product_title'].apply(converter.convert)\n",
    "df_dev_en['product_title']    = df_dev_en['product_title'].apply(converter.convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p = emoji.get_emoji_regexp()\n",
    "df_train_tcn['product_title'] = [re.sub(p, r\"\", x) for x in df_train_tcn['product_title'].tolist()]\n",
    "df_train_en['product_title']  = [re.sub(p, r\"\", x) for x in df_train_en['product_title'].tolist()]\n",
    "df_test_tcn['product_title']  = [re.sub(p, r\"\", x) for x in df_test_tcn['product_title'].tolist()]\n",
    "df_dev_tcn['product_title']   = [re.sub(p, r\"\", x) for x in df_dev_tcn['product_title'].tolist()]\n",
    "df_dev_en['product_title']    = [re.sub(p, r\"\", x) for x in df_dev_en['product_title'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tcn = df_train_tcn[['product_title']]\n",
    "df_train_en  = df_train_en[['product_title']]\n",
    "df_test_tcn  = df_test_tcn[['product_title']]\n",
    "df_dev_tcn   = df_dev_tcn[['product_title']]\n",
    "df_dev_en    = df_dev_en[['product_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mono_train_tcn, df_mono_valid_tcn, df_mono_train_en, df_mono_valid_en = \\\n",
    "    train_test_split(df_train_tcn.iloc[:499744], df_train_en.iloc[:499744], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_para_train_tcn, df_para_valid_tcn, df_para_train_en, df_para_valid_en = \\\n",
    "    train_test_split(df_dev_tcn, df_dev_en, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mono_train_tcn.to_csv('mass/data/mono/train.zh', header=False, index=False)\n",
    "df_mono_train_en.to_csv('mass/data/mono/train.en', header=False, index=False)\n",
    "df_mono_valid_tcn.to_csv('mass/data/mono/valid.zh', header=False, index=False)\n",
    "df_mono_valid_en.to_csv('mass/data/mono/valid.en', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_para_train_tcn.to_csv('mass/data/para/train.zh', header=False, index=False)\n",
    "df_para_train_en.to_csv('mass/data/para/train.en', header=False, index=False)\n",
    "df_para_valid_tcn.to_csv('mass/data/para/valid.zh', header=False, index=False)\n",
    "df_para_valid_en.to_csv('mass/data/para/valid.en', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
