{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import ast\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as tfk\n",
    "from transformers import DistilBertTokenizerFast, TFDistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-multilingual-cased were not used when initializing TFDistilBertModel: ['vocab_layer_norm', 'vocab_transform', 'vocab_projector', 'activation_13']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
    "bert_model = TFDistilBertModel.from_pretrained(\"distilbert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>annot</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/shopee-product-detection-student...</td>\n",
       "      <td>[]</td>\n",
       "      <td>7185852fa0825cd6c22b80b993f29201.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/shopee-product-detection-student...</td>\n",
       "      <td>[Torgan]</td>\n",
       "      <td>bc6f8e3ac0521feece25805210c0cc54.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/shopee-product-detection-student...</td>\n",
       "      <td>[ONGKIR, GRATIS, BOLDE]</td>\n",
       "      <td>aa98fd2aeeae32d59d4a3147aa621308.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/shopee-product-detection-student...</td>\n",
       "      <td>[]</td>\n",
       "      <td>d598d0d8413271ae2a5dc6d9344435f5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/shopee-product-detection-student...</td>\n",
       "      <td>[]</td>\n",
       "      <td>14dc17b840e686b9a8a8889376cccac8.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path                    annot  \\\n",
       "0  /kaggle/input/shopee-product-detection-student...                       []   \n",
       "1  /kaggle/input/shopee-product-detection-student...                 [Torgan]   \n",
       "2  /kaggle/input/shopee-product-detection-student...  [ONGKIR, GRATIS, BOLDE]   \n",
       "3  /kaggle/input/shopee-product-detection-student...                       []   \n",
       "4  /kaggle/input/shopee-product-detection-student...                       []   \n",
       "\n",
       "                               filename  \n",
       "0  7185852fa0825cd6c22b80b993f29201.jpg  \n",
       "1  bc6f8e3ac0521feece25805210c0cc54.jpg  \n",
       "2  aa98fd2aeeae32d59d4a3147aa621308.jpg  \n",
       "3  d598d0d8413271ae2a5dc6d9344435f5.jpg  \n",
       "4  14dc17b840e686b9a8a8889376cccac8.jpg  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"shopee-product-detection-dataset/test.csv\")\n",
    "df_extra = pd.read_csv(\"extra-features/test_ocr.csv\")\n",
    "df_extra['filename'] = df_extra['path'].apply(lambda x : x[62:])\n",
    "df_extra['annot']    = df_extra['annot'].apply(lambda x : ast.literal_eval(x))\n",
    "df_extra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>path</th>\n",
       "      <th>annot</th>\n",
       "      <th>annot_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fd663cf2b6e1d7b02938c6aaae0a32d2.jpg</td>\n",
       "      <td>43</td>\n",
       "      <td>/kaggle/input/shopee-product-detection-student...</td>\n",
       "      <td>[meia, WA082115556800, meraah, (kios]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c7fd77508a8c355eaab0d4e10efd6b15.jpg</td>\n",
       "      <td>43</td>\n",
       "      <td>/kaggle/input/shopee-product-detection-student...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127f3e6d6e3491b2459812353f33a913.jpg</td>\n",
       "      <td>43</td>\n",
       "      <td>/kaggle/input/shopee-product-detection-student...</td>\n",
       "      <td>[Shopee, Girl, R, id, COCOO]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ca4f2da11eda083064e6c36f37eeb81.jpg</td>\n",
       "      <td>43</td>\n",
       "      <td>/kaggle/input/shopee-product-detection-student...</td>\n",
       "      <td>[BICYCLE, HELMETS]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46d681a542f2c71be017eef6aae23313.jpg</td>\n",
       "      <td>43</td>\n",
       "      <td>/kaggle/input/shopee-product-detection-student...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               filename  category  \\\n",
       "0  fd663cf2b6e1d7b02938c6aaae0a32d2.jpg        43   \n",
       "1  c7fd77508a8c355eaab0d4e10efd6b15.jpg        43   \n",
       "2  127f3e6d6e3491b2459812353f33a913.jpg        43   \n",
       "3  5ca4f2da11eda083064e6c36f37eeb81.jpg        43   \n",
       "4  46d681a542f2c71be017eef6aae23313.jpg        43   \n",
       "\n",
       "                                                path  \\\n",
       "0  /kaggle/input/shopee-product-detection-student...   \n",
       "1  /kaggle/input/shopee-product-detection-student...   \n",
       "2  /kaggle/input/shopee-product-detection-student...   \n",
       "3  /kaggle/input/shopee-product-detection-student...   \n",
       "4  /kaggle/input/shopee-product-detection-student...   \n",
       "\n",
       "                                   annot  annot_len  \n",
       "0  [meia, WA082115556800, meraah, (kios]          4  \n",
       "1                                     []          0  \n",
       "2           [Shopee, Girl, R, id, COCOO]          5  \n",
       "3                     [BICYCLE, HELMETS]          2  \n",
       "4                                    [3]          1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = df.merge(df_extra, how=\"left\", on=\"filename\")\n",
    "for row in df_.loc[df_.annot.isnull(), 'annot'].index:\n",
    "    df_.at[row, 'annot'] = []\n",
    "df_['annot_len'] = df_['annot'].apply(lambda x : len(x))\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1000.0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_['annot_len'], bins=np.arange(65)-0.5)\n",
    "plt.xlim((-1, 65))\n",
    "plt.ylim(0, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for i in range(len(df_)):\n",
    "    x =  np.array(tokenizer.encode(' '.join(df_['annot'].iloc[i]), truncation=True, padding='max_length', add_special_tokens=True, max_length=64))\n",
    "    assert(len(x) == 64)\n",
    "    X.append(x)\n",
    "\n",
    "X = np.array(X)\n",
    "# Y = tfk.utils.to_categorical(df_['category'], num_classes=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-79a36c98e814>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_in   = tfk.layers.Input(shape=(64,), name='input_token', dtype='int32')\n",
    "bert_model.trainable=False\n",
    "\n",
    "embedding_layer = bert_model(input_ids_in)[0]\n",
    "embedding_slice = embedding_layer[:,0,:]\n",
    "x = tfk.layers.Dense(42, activation='softmax')(embedding_slice)\n",
    "model = tf.keras.Model(inputs=input_ids_in, outputs=x)\n",
    "model_embedding = tf.keras.Model(inputs=input_ids_in, outputs=embedding_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_token (InputLayer)     [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "tf_distil_bert_model (TFDist ((None, 64, 768),)        134734080 \n",
      "_________________________________________________________________\n",
      "tf_op_layer_strided_slice (T [(None, 768)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 42)                32298     \n",
      "=================================================================\n",
      "Total params: 134,766,378\n",
      "Trainable params: 32,298\n",
      "Non-trainable params: 134,734,080\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "early_stop = tfk.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.compile(optimizer=tfk.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tfk.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "200/200 [==============================] - 56s 278ms/step - loss: 3.5060 - accuracy: 0.0886 - val_loss: 5.6380 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 2/15\n",
      "200/200 [==============================] - 54s 272ms/step - loss: 3.4728 - accuracy: 0.1052 - val_loss: 5.6512 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 3/15\n",
      "200/200 [==============================] - 55s 273ms/step - loss: 3.4447 - accuracy: 0.1122 - val_loss: 5.6545 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 4/15\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 3.4356 - accuracy: 0.1173 - val_loss: 5.6543 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 5/15\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 3.4188 - accuracy: 0.1220 - val_loss: 5.6691 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 6/15\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 3.4081 - accuracy: 0.1268 - val_loss: 5.6518 - val_accuracy: 0.0000e+00 - lr: 0.0010\n",
      "Epoch 7/15\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 3.3851 - accuracy: 0.1332 - val_loss: 5.6452 - val_accuracy: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 8/15\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 3.3823 - accuracy: 0.1375 - val_loss: 5.6421 - val_accuracy: 3.9063e-04 - lr: 2.0000e-04\n",
      "Epoch 9/15\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 3.3773 - accuracy: 0.1383 - val_loss: 5.6512 - val_accuracy: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 10/15\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 3.3824 - accuracy: 0.1385 - val_loss: 5.6498 - val_accuracy: 0.0000e+00 - lr: 2.0000e-04\n",
      "Epoch 11/15\n",
      "200/200 [==============================] - 55s 274ms/step - loss: 3.3732 - accuracy: 0.1408 - val_loss: 5.6622 - val_accuracy: 0.0000e+00 - lr: 2.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c98c2677b8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y,\n",
    "          epochs=15,\n",
    "          batch_size=128,\n",
    "          steps_per_epoch=200,\n",
    "          validation_steps=20,\n",
    "          validation_split=0.1,\n",
    "          callbacks=[reduce_lr,\n",
    "                     early_stop, \n",
    "                     #checkpoint, \n",
    "                     #tensorboard_callback,\n",
    "                     #lr_tensorboard_callback,\n",
    "                     #tqdm_callback\n",
    "                    ]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 26s 69ms/step\n"
     ]
    }
   ],
   "source": [
    "emb = model_embedding.predict(X, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12186, 768)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb = pd.DataFrame(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>annot_len</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fd663cf2b6e1d7b02938c6aaae0a32d2.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>0.301740</td>\n",
       "      <td>0.035642</td>\n",
       "      <td>0.645422</td>\n",
       "      <td>0.184393</td>\n",
       "      <td>0.300565</td>\n",
       "      <td>-0.110420</td>\n",
       "      <td>-0.429352</td>\n",
       "      <td>-0.088092</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096835</td>\n",
       "      <td>0.455804</td>\n",
       "      <td>-0.353963</td>\n",
       "      <td>-0.642146</td>\n",
       "      <td>-0.174284</td>\n",
       "      <td>-0.118974</td>\n",
       "      <td>0.011540</td>\n",
       "      <td>0.537465</td>\n",
       "      <td>0.274709</td>\n",
       "      <td>-0.274494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c7fd77508a8c355eaab0d4e10efd6b15.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.226755</td>\n",
       "      <td>-0.063037</td>\n",
       "      <td>0.575984</td>\n",
       "      <td>0.141175</td>\n",
       "      <td>0.276204</td>\n",
       "      <td>-0.093213</td>\n",
       "      <td>-0.494611</td>\n",
       "      <td>0.059598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.421785</td>\n",
       "      <td>-0.216663</td>\n",
       "      <td>-0.693786</td>\n",
       "      <td>-0.090551</td>\n",
       "      <td>-0.078733</td>\n",
       "      <td>0.101649</td>\n",
       "      <td>0.539371</td>\n",
       "      <td>0.334486</td>\n",
       "      <td>-0.248356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127f3e6d6e3491b2459812353f33a913.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>0.230122</td>\n",
       "      <td>0.014947</td>\n",
       "      <td>0.629470</td>\n",
       "      <td>0.201817</td>\n",
       "      <td>0.197289</td>\n",
       "      <td>-0.100137</td>\n",
       "      <td>-0.524586</td>\n",
       "      <td>-0.013994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043481</td>\n",
       "      <td>0.401430</td>\n",
       "      <td>-0.290804</td>\n",
       "      <td>-0.698697</td>\n",
       "      <td>-0.118225</td>\n",
       "      <td>-0.046748</td>\n",
       "      <td>0.030550</td>\n",
       "      <td>0.569611</td>\n",
       "      <td>0.310742</td>\n",
       "      <td>-0.270135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5ca4f2da11eda083064e6c36f37eeb81.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0.243957</td>\n",
       "      <td>0.050931</td>\n",
       "      <td>0.617198</td>\n",
       "      <td>0.097470</td>\n",
       "      <td>0.213967</td>\n",
       "      <td>-0.092841</td>\n",
       "      <td>-0.494858</td>\n",
       "      <td>0.011114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109203</td>\n",
       "      <td>0.449101</td>\n",
       "      <td>-0.221006</td>\n",
       "      <td>-0.673565</td>\n",
       "      <td>-0.062738</td>\n",
       "      <td>-0.074305</td>\n",
       "      <td>0.041812</td>\n",
       "      <td>0.539332</td>\n",
       "      <td>0.329217</td>\n",
       "      <td>-0.252538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46d681a542f2c71be017eef6aae23313.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0.234347</td>\n",
       "      <td>-0.052357</td>\n",
       "      <td>0.601979</td>\n",
       "      <td>0.129921</td>\n",
       "      <td>0.276907</td>\n",
       "      <td>-0.088497</td>\n",
       "      <td>-0.478140</td>\n",
       "      <td>0.046975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008686</td>\n",
       "      <td>0.435282</td>\n",
       "      <td>-0.194707</td>\n",
       "      <td>-0.727289</td>\n",
       "      <td>-0.096276</td>\n",
       "      <td>-0.076775</td>\n",
       "      <td>0.094808</td>\n",
       "      <td>0.559078</td>\n",
       "      <td>0.342450</td>\n",
       "      <td>-0.254133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               filename  annot_len         0         1  \\\n",
       "0  fd663cf2b6e1d7b02938c6aaae0a32d2.jpg          4  0.301740  0.035642   \n",
       "1  c7fd77508a8c355eaab0d4e10efd6b15.jpg          0  0.226755 -0.063037   \n",
       "2  127f3e6d6e3491b2459812353f33a913.jpg          5  0.230122  0.014947   \n",
       "3  5ca4f2da11eda083064e6c36f37eeb81.jpg          2  0.243957  0.050931   \n",
       "4  46d681a542f2c71be017eef6aae23313.jpg          1  0.234347 -0.052357   \n",
       "\n",
       "          2         3         4         5         6         7  ...       758  \\\n",
       "0  0.645422  0.184393  0.300565 -0.110420 -0.429352 -0.088092  ... -0.096835   \n",
       "1  0.575984  0.141175  0.276204 -0.093213 -0.494611  0.059598  ...  0.001799   \n",
       "2  0.629470  0.201817  0.197289 -0.100137 -0.524586 -0.013994  ... -0.043481   \n",
       "3  0.617198  0.097470  0.213967 -0.092841 -0.494858  0.011114  ... -0.109203   \n",
       "4  0.601979  0.129921  0.276907 -0.088497 -0.478140  0.046975  ... -0.008686   \n",
       "\n",
       "        759       760       761       762       763       764       765  \\\n",
       "0  0.455804 -0.353963 -0.642146 -0.174284 -0.118974  0.011540  0.537465   \n",
       "1  0.421785 -0.216663 -0.693786 -0.090551 -0.078733  0.101649  0.539371   \n",
       "2  0.401430 -0.290804 -0.698697 -0.118225 -0.046748  0.030550  0.569611   \n",
       "3  0.449101 -0.221006 -0.673565 -0.062738 -0.074305  0.041812  0.539332   \n",
       "4  0.435282 -0.194707 -0.727289 -0.096276 -0.076775  0.094808  0.559078   \n",
       "\n",
       "        766       767  \n",
       "0  0.274709 -0.274494  \n",
       "1  0.334486 -0.248356  \n",
       "2  0.310742 -0.270135  \n",
       "3  0.329217 -0.252538  \n",
       "4  0.342450 -0.254133  \n",
       "\n",
       "[5 rows x 770 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = df_[['filename', 'annot_len']].merge(df_emb, on=df_.index).drop('key_0', axis=1)\n",
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_csv(\"shopee-product-detection-dataset/test_with_emb.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
